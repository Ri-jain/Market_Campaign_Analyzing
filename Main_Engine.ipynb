{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f541cf47-f174-4824-9879-0defa0cfd83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: big_google_ads_data.csv...\n",
      "Aggregating data and running audit logic...\n",
      "\n",
      "==============================\n",
      " AUDIT REPORT \n",
      "==============================\n",
      "Total Opportunity Identified: $1,452,814.27\n",
      "• CRITICAL: $410,166.44 wasted on 14 campaigns with ZERO conversions.\n",
      "• WARNING: $1,042,647.83 detected in 'Zombie' campaigns (ROAS < 1.0).\n",
      "\n",
      "[FIX THIS FIRST]\n",
      "Campaign: 'Campaign_042_ZOMBIE'\n",
      "Problem: Spent $55,630.68 with ROAS of 0.50.\n",
      "Action: Pause immediately.\n",
      "\n",
      "[ACTION] Detailed list of 35 bad campaigns saved to: audit_results_BAD_CAMPAIGNS.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# PART 1: CONFIGURATION\n",
    "# ==========================================\n",
    "THRESHOLDS = {\n",
    "    'ZERO_CONV_THRESHOLD': 50.0,   # Max spend allowed with 0 conversions before flagging\n",
    "    'ZOMBIE_ROAS': 1.0,            # Minimum acceptable ROAS (Revenue / Spend)\n",
    "    'ZOMBIE_SPEND_MIN': 100.0      # Minimum spend to qualify as a \"Zombie\"\n",
    "}\n",
    "\n",
    "# Map your CSV headers to these standard names\n",
    "COLUMN_MAPPING = {\n",
    "    'Day': 'date',\n",
    "    'Campaign': 'campaign_name',\n",
    "    'Cost': 'spend',\n",
    "    'Impressions': 'impressions',\n",
    "    'Clicks': 'clicks',\n",
    "    'Conversions': 'conversions',\n",
    "    'Total conv. value': 'revenue'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: INGESTION\n",
    "# ==========================================\n",
    "def load_data(filename):\n",
    "    print(f\"Loading data from: {filename}...\")\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"ERROR: Could not find {filename}. Make sure it is in this folder.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading CSV: {e}\")\n",
    "        return None\n",
    "        \n",
    "    # Rename columns based on mapping\n",
    "    df = df.rename(columns=COLUMN_MAPPING)\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['campaign_name', 'spend', 'conversions', 'revenue']\n",
    "    missing = [col for col in required_cols if col not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"ERROR: Missing required columns: {missing}\")\n",
    "        print(f\"Current columns found: {list(df.columns)}\")\n",
    "        return None\n",
    "\n",
    "    if 'date' in df.columns:\n",
    "        # 'mixed' allows handling 17/12/24 OR 2024-12-17 automatically\n",
    "        df['date'] = pd.to_datetime(df['date'], format='mixed', dayfirst=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: ANALYSIS\n",
    "# ==========================================\n",
    "def analyze_campaigns(df):\n",
    "    print(\"Aggregating data and running audit logic...\")\n",
    "    \n",
    "    # 1. Aggregate Daily Data into Campaign Totals\n",
    "    # We use 'sum' for metrics to get lifetime stats from the daily rows\n",
    "    camp_stats = df.groupby('campaign_name').agg({\n",
    "        'spend': 'sum',\n",
    "        'conversions': 'sum',\n",
    "        'revenue': 'sum',\n",
    "        'clicks': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 2. Calculate KPIs (Math)\n",
    "    # np.where is used to prevent \"Divide by Zero\" errors\n",
    "    camp_stats['roas'] = np.where(camp_stats['spend'] > 0, camp_stats['revenue'] / camp_stats['spend'], 0)\n",
    "    camp_stats['cpa'] = np.where(camp_stats['conversions'] > 0, camp_stats['spend'] / camp_stats['conversions'], 0)\n",
    "\n",
    "    # 3. Apply Logic Flags (The \"Audit\")\n",
    "    \n",
    "    # Flag 1: ZERO HOPE\n",
    "    # Campaigns that have spent significant money but produced 0 conversions.\n",
    "    camp_stats['is_zero_hope'] = (camp_stats['spend'] > THRESHOLDS['ZERO_CONV_THRESHOLD']) & (camp_stats['conversions'] == 0)\n",
    "    \n",
    "    # Flag 2: ZOMBIES\n",
    "    # Campaigns that are getting conversions, but doing so unprofitably (ROAS < 1.0) \n",
    "    # and have spent enough to be statistically significant.\n",
    "    camp_stats['is_zombie'] = (\n",
    "        (camp_stats['spend'] > THRESHOLDS['ZOMBIE_SPEND_MIN']) & \n",
    "        (camp_stats['roas'] < THRESHOLDS['ZOMBIE_ROAS']) & \n",
    "        (camp_stats['conversions'] > 0)\n",
    "    )\n",
    "    \n",
    "    return camp_stats\n",
    "\n",
    "# ==========================================\n",
    "# PART 4: INSIGHT TRANSLATION\n",
    "# ==========================================\n",
    "def generate_insights(df):\n",
    "    insights = []\n",
    "    \n",
    "    zero_hope = df[df['is_zero_hope'] == True]\n",
    "    zombies = df[df['is_zombie'] == True]\n",
    "    \n",
    "    wasted_spend = zero_hope['spend'].sum()\n",
    "    inefficient_spend = zombies['spend'].sum()\n",
    "    total_bleed = wasted_spend + inefficient_spend\n",
    "    \n",
    "    insights.append(f\"Total Opportunity Identified: ${total_bleed:,.2f}\")\n",
    "    \n",
    "    if wasted_spend > 0:\n",
    "        insights.append(f\"• CRITICAL: ${wasted_spend:,.2f} wasted on {len(zero_hope)} campaigns with ZERO conversions.\")\n",
    "        \n",
    "    if inefficient_spend > 0:\n",
    "        insights.append(f\"• WARNING: ${inefficient_spend:,.2f} detected in 'Zombie' campaigns (ROAS < 1.0).\")\n",
    "\n",
    "    # Find worst offender to highlight\n",
    "    bad_campaigns = pd.concat([zero_hope, zombies])\n",
    "    if not bad_campaigns.empty:\n",
    "        # Sort by highest spend to find the biggest problem\n",
    "        worst_offender = bad_campaigns.sort_values(by='spend', ascending=False).iloc[0]\n",
    "        \n",
    "        fix_msg = (\n",
    "            f\"\\n[FIX THIS FIRST]\\n\"\n",
    "            f\"Campaign: '{worst_offender['campaign_name']}'\\n\"\n",
    "            f\"Problem: Spent ${worst_offender['spend']:,.2f} with ROAS of {worst_offender['roas']:.2f}.\\n\"\n",
    "            f\"Action: Pause immediately.\"\n",
    "        )\n",
    "        insights.append(fix_msg)\n",
    "        \n",
    "    return insights\n",
    "\n",
    "# ==========================================\n",
    "# PART 5: EXECUTION (The \"Main\" Loop)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Define your filename here\n",
    "    FILENAME = 'big_google_ads_data.csv' \n",
    "    \n",
    "    # 2. Run the pipeline\n",
    "    df_raw = load_data(FILENAME)\n",
    "    \n",
    "    if df_raw is not None:\n",
    "        # Run the audit\n",
    "        audit_results = analyze_campaigns(df_raw)\n",
    "        \n",
    "        # Generate and print text insights\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(\" AUDIT REPORT \")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        text_report = generate_insights(audit_results)\n",
    "        for line in text_report:\n",
    "            print(line)\n",
    "            \n",
    "        # 3. EXPORT: Save the bad campaigns to a file for review\n",
    "        # Filter for only the bad ones\n",
    "        bad_campaigns = audit_results[\n",
    "            (audit_results['is_zero_hope'] == True) | \n",
    "            (audit_results['is_zombie'] == True)\n",
    "        ].copy()\n",
    "        \n",
    "        if not bad_campaigns.empty:\n",
    "            output_file = 'audit_results_BAD_CAMPAIGNS.xlsx'\n",
    "            try:\n",
    "                bad_campaigns.to_excel(output_file, index=False)\n",
    "                print(f\"\\n[ACTION] Detailed list of {len(bad_campaigns)} bad campaigns saved to: {output_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n[ERROR] Could not save Excel file. Is it open? Error: {e}\")\n",
    "        else:\n",
    "            print(\"\\n[GOOD NEWS] No bad campaigns found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95eb4cf9-d756-4d04-a474-ed93bbdc25d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /opt/anaconda3/lib/python3.11/site-packages (1.30.0)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (7.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.18.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from validators<1,>=0.2->streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit plotly pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989b518-fb0b-4660-a2d1-de0a5692e346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
